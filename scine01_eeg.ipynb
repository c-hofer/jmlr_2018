{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch2/chofer/opt/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(123)\n",
    "import random\n",
    "random.seed(123)\n",
    "\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import shutil\n",
    "import itertools\n",
    "import sklearn.cluster\n",
    "\n",
    "from chofer_torchex.utils.functional import collection_cascade, cuda_cascade\n",
    "\n",
    "from chofer_tda_datasets import SciNe01EEGBottomTopFiltration\n",
    "from chofer_tda_datasets.transforms import Hdf5GroupToDictSelector\n",
    "\n",
    "from jmlr_2018_code.utils import *\n",
    "from chofer_torchex.nn.slayer import SLayerExponential, \\\n",
    "SLayerRational, \\\n",
    "LinearRationalStretchedBirthLifeTimeCoordinateTransform, \\\n",
    "prepare_batch, SLayerRationalHat\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from collections import Counter, defaultdict\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import OrderedDict\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "%matplotlib notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(3)\n",
    "\n",
    "\n",
    "class train_env:\n",
    "    nu = 0.1\n",
    "    n_epochs = 200\n",
    "    lr_initial = 0.5\n",
    "    momentum = 0.9\n",
    "    lr_epoch_step = 20\n",
    "    batch_size = 100\n",
    "    train_size = 0.9\n",
    "    \n",
    "\n",
    "coordinate_transform = LinearRationalStretchedBirthLifeTimeCoordinateTransform(nu=train_env.nu)\n",
    "\n",
    "dataset = SciNe01EEGBottomTopFiltration(data_root_folder_path='/scratch1/chofer/jmlr2018_data/')\n",
    "sensor_indices = [str(i) for i in dataset.sensor_configurations['low_resolution_whole_head']]\n",
    "selection = {'top': sensor_indices, 'bottom': sensor_indices}\n",
    "selector = Hdf5GroupToDictSelector(selection)\n",
    "\n",
    "dataset.data_transforms = [\n",
    "                           selector,\n",
    "                           numpy_to_torch_cascade,                              \n",
    "                           lambda x: collection_cascade(x, \n",
    "                                                        lambda x: isinstance(x, torch._TensorBase), \n",
    "                                                        lambda x: coordinate_transform(x)),\n",
    "                           ]\n",
    "\n",
    "dataset.target_transforms = [lambda x: int(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_scine01_sample_target_iter(sample_target_iter):\n",
    "    x, y = defaultdict(lambda: defaultdict(list)), []\n",
    "        \n",
    "    for x_i, y_i in sample_target_iter:\n",
    "        y.append(y_i)\n",
    "\n",
    "        for k, v in x_i.items():\n",
    "            for kk, dgm in v.items():\n",
    "                x[k][kk].append(dgm)    \n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "class Scine01Collate:   \n",
    "    def __init__(self, cuda=True):\n",
    "        self.cuda = cuda\n",
    "        \n",
    "    def __call__(self, sample_target_iter):\n",
    "        x, y = concat_scine01_sample_target_iter(sample_target_iter)\n",
    "\n",
    "        y = torch.LongTensor(y)    \n",
    "        \n",
    "        x = collection_cascade(x,\n",
    "                           lambda xx: isinstance(xx, list),\n",
    "                           lambda xx: prepare_batch(xx, 2)) \n",
    "        \n",
    "        if self.cuda:\n",
    "            # Shifting the necessary parts of the prepared batch to the cuda\n",
    "            x = collection_cascade(x,\n",
    "                                   lambda xx: isinstance(xx, tuple),\n",
    "                                  lambda xx: (xx[0].cuda(), xx[1].cuda(), xx[2], xx[3]))\n",
    "            y = y.cuda()\n",
    "\n",
    "        return x, y                       \n",
    "    \n",
    "collate_fn = Scine01Collate(cuda=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Slayer(n_elements):\n",
    "    return SLayerRationalHat(n_elements, radius_init=10, exponent=1)\n",
    "\n",
    "def LinearCell(n_in, n_out):\n",
    "    m = nn.Sequential(nn.Linear(n_in, n_out), \n",
    "                      nn.BatchNorm1d(n_out), \n",
    "                      nn.ReLU(),\n",
    "                     )\n",
    "    m.out_features = m[0].out_features\n",
    "    return m\n",
    "\n",
    "\n",
    "class Scine01Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()   \n",
    "        self.n_elements = 25\n",
    "        \n",
    "        self.slayers = ModuleDict()\n",
    "        for k, indices in selection.items():\n",
    "            self.slayers[k] = ModuleDict()\n",
    "            for kk in indices:\n",
    "                s = Slayer(self.n_elements)\n",
    "                self.slayers[k][kk] = nn.Sequential(s\n",
    "                                                   )    \n",
    "            \n",
    "        cls_in_dim = self.n_elements * 2 * len(sensor_indices)\n",
    "        n_1 = 2*cls_in_dim\n",
    "        print('cls_in_dim', cls_in_dim)\n",
    "        self.cls = nn.Sequential(\n",
    "                                nn.Dropout(0.01), \n",
    "                                LinearCell(cls_in_dim, n_1),\n",
    "                                LinearCell(n_1, int(n_1/4)),    \n",
    "#                                 LinearCell(int(n_1/4), int(n_1/16)),   \n",
    "#                                 nn.Dropout(0.1),\n",
    "                                nn.Linear(int(n_1/4), 7))\n",
    "        \n",
    "    def forward(self, input):\n",
    "        x = []\n",
    "        for k, v in input.items():\n",
    "            for kk, dgm in v.items():            \n",
    "                x.append(self.slayers[k][kk](dgm))\n",
    "        x = torch.cat(x, dim=1)          \n",
    "        x = self.cls(x)       \n",
    "                                              \n",
    "        return x\n",
    "    \n",
    "    def center_init(self, sample_target_iter):        \n",
    "        \n",
    "        #reducing number of samples for initalization becaus of run-time reasons\n",
    "#         n_samples = int(len(sample_target_iter)/1000)\n",
    "#         sample_target_iter_reduced = list(sample_target_iter)[:n_samples]        \n",
    "        \n",
    "        x, _ = concat_scine01_sample_target_iter(sample_target_iter)\n",
    "        \n",
    "        def prepare_for_knn(samples):\n",
    "            samples = torch.cat(samples, dim=0)\n",
    "            samples = list({tuple(row) for row in samples})\n",
    "            samples = np.array(samples)\n",
    "            return samples              \n",
    "        \n",
    "        x = collection_cascade(x, stop_predicate=lambda e: isinstance(e, list), \n",
    "                                  function_to_apply=prepare_for_knn) \n",
    "        \n",
    "        for k, v in x.items():\n",
    "            for kk, dgm in v.items():                  \n",
    "                kmeans = sklearn.cluster.KMeans(n_clusters=self.n_elements, init='k-means++', random_state=123, n_init=1)                           \n",
    "                kmeans.fit(dgm)\n",
    "                centers = kmeans.cluster_centers_\n",
    "                centers = torch.from_numpy(centers).float()\n",
    "                self.slayers[k][kk][0].centers.data = centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run 0\n",
      "cls_in_dim 1000\n",
      "Epoch 1/200, Batch 284/284       \n",
      "0.21714285714285714\n",
      "Epoch 2/200, Batch 12/284       \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-28:\n",
      "Process Process-22:\n",
      "Process Process-21:\n",
      "Process Process-23:\n",
      "Process Process-30:\n",
      "Process Process-24:\n",
      "Process Process-27:\n",
      "Process Process-25:\n",
      "Process Process-26:\n",
      "Process Process-29:\n",
      "Traceback (most recent call last):\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 59, in _worker_loop\n",
      "    data_queue.put((idx, samples))\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 346, in put\n",
      "    with self._wlock:\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/pma/chofer/repositories/chofer_tda_datasets/chofer_tda_datasets/utils/h5py_dataset.py\", line 28, in __getitem__\n",
      "    x = t(x)\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/pma/chofer/repositories/chofer_tda_datasets/chofer_tda_datasets/transforms.py\", line 38, in __call__\n",
      "    return self.__select(data_grp, self.key_selection)\n",
      "  File \"/home/pma/chofer/repositories/chofer_tda_datasets/chofer_tda_datasets/utils/h5py_dataset.py\", line 28, in __getitem__\n",
      "    x = t(x)\n",
      "  File \"/home/pma/chofer/repositories/chofer_tda_datasets/chofer_tda_datasets/transforms.py\", line 31, in __select\n",
      "    return {k: self.__select(data_grp[k], v) for k, v in selection.items()}\n",
      "  File \"/home/pma/chofer/repositories/chofer_tda_datasets/chofer_tda_datasets/transforms.py\", line 38, in __call__\n",
      "    return self.__select(data_grp, self.key_selection)\n",
      "  File \"/home/pma/chofer/repositories/chofer_tda_datasets/chofer_tda_datasets/transforms.py\", line 31, in <dictcomp>\n",
      "    return {k: self.__select(data_grp[k], v) for k, v in selection.items()}\n",
      "  File \"/home/pma/chofer/repositories/chofer_tda_datasets/chofer_tda_datasets/transforms.py\", line 31, in __select\n",
      "    return {k: self.__select(data_grp[k], v) for k, v in selection.items()}\n",
      "  File \"/home/pma/chofer/repositories/chofer_tda_datasets/chofer_tda_datasets/transforms.py\", line 34, in __select\n",
      "    return {k: data_grp[k].value for k in selection}\n",
      "  File \"/home/pma/chofer/repositories/chofer_tda_datasets/chofer_tda_datasets/transforms.py\", line 31, in <dictcomp>\n",
      "    return {k: self.__select(data_grp[k], v) for k, v in selection.items()}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pma/chofer/repositories/chofer_tda_datasets/chofer_tda_datasets/transforms.py\", line 34, in <dictcomp>\n",
      "    return {k: data_grp[k].value for k in selection}\n",
      "  File \"/home/pma/chofer/repositories/chofer_tda_datasets/chofer_tda_datasets/transforms.py\", line 34, in __select\n",
      "    return {k: data_grp[k].value for k in selection}\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"/home/pma/chofer/repositories/chofer_tda_datasets/chofer_tda_datasets/transforms.py\", line 34, in <dictcomp>\n",
      "    return {k: data_grp[k].value for k in selection}\n",
      "Traceback (most recent call last):\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/site-packages/h5py/_hl/dataset.py\", line 250, in value\n",
      "    return self[()]\n",
      "  File \"<ipython-input-2-d7d9ed558bb7>\", line 25, in __call__\n",
      "    lambda xx: prepare_batch(xx, 2))\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/site-packages/h5py/_hl/dataset.py\", line 250, in value\n",
      "    return self[()]\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"/home/pma/chofer/repositories/chofer_torchex/chofer_torchex/utils/functional.py\", line 14, in collection_cascade\n",
      "    function_to_apply=function_to_apply) for k, v in input.items()}\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 59, in _worker_loop\n",
      "    data_queue.put((idx, samples))\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"/home/pma/chofer/repositories/chofer_torchex/chofer_torchex/utils/functional.py\", line 14, in <dictcomp>\n",
      "    function_to_apply=function_to_apply) for k, v in input.items()}\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 347, in put\n",
      "    self._writer.send_bytes(obj)\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/site-packages/h5py/_hl/dataset.py\", line 429, in __getitem__\n",
      "    new_dtype = readtime_dtype(self.id.dtype, names)\n",
      "  File \"/home/pma/chofer/repositories/chofer_torchex/chofer_torchex/utils/functional.py\", line 14, in collection_cascade\n",
      "    function_to_apply=function_to_apply) for k, v in input.items()}\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/site-packages/h5py/_hl/dataset.py\", line 485, in __getitem__\n",
      "    arr = numpy.ndarray(mshape, new_dtype, order='C')\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/pma/chofer/repositories/chofer_torchex/chofer_torchex/utils/functional.py\", line 14, in <dictcomp>\n",
      "    function_to_apply=function_to_apply) for k, v in input.items()}\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/pma/chofer/repositories/chofer_torchex/chofer_torchex/utils/functional.py\", line 6, in collection_cascade\n",
      "    return function_to_apply(input)\n",
      "  File \"<ipython-input-2-d7d9ed558bb7>\", line 25, in <lambda>\n",
      "    lambda xx: prepare_batch(xx, 2))\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "  File \"/home/pma/chofer/repositories/chofer_torchex/chofer_torchex/nn/slayer.py\", line 79, in prepare_batch\n",
      "    prepared_dgm.index_add_(0, index_selection, multi_set)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/pma/chofer/repositories/chofer_tda_datasets/chofer_tda_datasets/utils/h5py_dataset.py\", line 28, in __getitem__\n",
      "    x = t(x)\n",
      "  File \"/home/pma/chofer/repositories/chofer_tda_datasets/chofer_tda_datasets/utils/h5py_dataset.py\", line 28, in __getitem__\n",
      "    x = t(x)\n",
      "  File \"/home/pma/chofer/repositories/chofer_tda_datasets/chofer_tda_datasets/utils/h5py_dataset.py\", line 28, in __getitem__\n",
      "    x = t(x)\n",
      "  File \"/home/pma/chofer/repositories/chofer_tda_datasets/chofer_tda_datasets/utils/h5py_dataset.py\", line 28, in __getitem__\n",
      "    x = t(x)\n",
      "  File \"/home/pma/chofer/repositories/chofer_tda_datasets/chofer_tda_datasets/transforms.py\", line 38, in __call__\n",
      "    return self.__select(data_grp, self.key_selection)\n",
      "  File \"/home/pma/chofer/repositories/chofer_tda_datasets/chofer_tda_datasets/transforms.py\", line 38, in __call__\n",
      "    return self.__select(data_grp, self.key_selection)\n",
      "  File \"/home/pma/chofer/repositories/chofer_tda_datasets/chofer_tda_datasets/transforms.py\", line 38, in __call__\n",
      "    return self.__select(data_grp, self.key_selection)\n",
      "  File \"/home/pma/chofer/repositories/chofer_tda_datasets/chofer_tda_datasets/transforms.py\", line 38, in __call__\n",
      "    return self.__select(data_grp, self.key_selection)\n",
      "  File \"/home/pma/chofer/repositories/chofer_tda_datasets/chofer_tda_datasets/transforms.py\", line 31, in __select\n",
      "    return {k: self.__select(data_grp[k], v) for k, v in selection.items()}\n",
      "  File \"/home/pma/chofer/repositories/chofer_tda_datasets/chofer_tda_datasets/transforms.py\", line 31, in __select\n",
      "    return {k: self.__select(data_grp[k], v) for k, v in selection.items()}\n",
      "  File \"/home/pma/chofer/repositories/chofer_tda_datasets/chofer_tda_datasets/transforms.py\", line 31, in <dictcomp>\n",
      "    return {k: self.__select(data_grp[k], v) for k, v in selection.items()}\n",
      "  File \"/home/pma/chofer/repositories/chofer_tda_datasets/chofer_tda_datasets/transforms.py\", line 31, in __select\n",
      "    return {k: self.__select(data_grp[k], v) for k, v in selection.items()}\n",
      "  File \"/home/pma/chofer/repositories/chofer_tda_datasets/chofer_tda_datasets/transforms.py\", line 31, in __select\n",
      "    return {k: self.__select(data_grp[k], v) for k, v in selection.items()}\n",
      "  File \"/home/pma/chofer/repositories/chofer_tda_datasets/chofer_tda_datasets/transforms.py\", line 31, in <dictcomp>\n",
      "    return {k: self.__select(data_grp[k], v) for k, v in selection.items()}\n",
      "  File \"/home/pma/chofer/repositories/chofer_tda_datasets/chofer_tda_datasets/transforms.py\", line 31, in <dictcomp>\n",
      "    return {k: self.__select(data_grp[k], v) for k, v in selection.items()}\n",
      "  File \"/home/pma/chofer/repositories/chofer_tda_datasets/chofer_tda_datasets/transforms.py\", line 34, in __select\n",
      "    return {k: data_grp[k].value for k in selection}\n",
      "  File \"/home/pma/chofer/repositories/chofer_tda_datasets/chofer_tda_datasets/transforms.py\", line 31, in <dictcomp>\n",
      "    return {k: self.__select(data_grp[k], v) for k, v in selection.items()}\n",
      "  File \"/home/pma/chofer/repositories/chofer_tda_datasets/chofer_tda_datasets/transforms.py\", line 34, in __select\n",
      "    return {k: data_grp[k].value for k in selection}\n",
      "  File \"/home/pma/chofer/repositories/chofer_tda_datasets/chofer_tda_datasets/transforms.py\", line 34, in <dictcomp>\n",
      "    return {k: data_grp[k].value for k in selection}\n",
      "  File \"/home/pma/chofer/repositories/chofer_tda_datasets/chofer_tda_datasets/transforms.py\", line 34, in __select\n",
      "    return {k: data_grp[k].value for k in selection}\n",
      "  File \"/home/pma/chofer/repositories/chofer_tda_datasets/chofer_tda_datasets/transforms.py\", line 34, in __select\n",
      "    return {k: data_grp[k].value for k in selection}\n",
      "  File \"/home/pma/chofer/repositories/chofer_tda_datasets/chofer_tda_datasets/transforms.py\", line 34, in <dictcomp>\n",
      "    return {k: data_grp[k].value for k in selection}\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"/home/pma/chofer/repositories/chofer_tda_datasets/chofer_tda_datasets/transforms.py\", line 34, in <dictcomp>\n",
      "    return {k: data_grp[k].value for k in selection}\n",
      "  File \"/home/pma/chofer/repositories/chofer_tda_datasets/chofer_tda_datasets/transforms.py\", line 34, in <dictcomp>\n",
      "    return {k: data_grp[k].value for k in selection}\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/site-packages/h5py/_hl/dataset.py\", line 250, in value\n",
      "    return self[()]\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/site-packages/h5py/_hl/group.py\", line 173, in __getitem__\n",
      "    return dataset.Dataset(oid)\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/site-packages/h5py/_hl/group.py\", line 167, in __getitem__\n",
      "    oid = h5o.open(self.id, self._e(name), lapl=self._lapl)\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/site-packages/h5py/_hl/group.py\", line 167, in __getitem__\n",
      "    oid = h5o.open(self.id, self._e(name), lapl=self._lapl)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/site-packages/h5py/_hl/dataset.py\", line 476, in __getitem__\n",
      "    selection = sel.select(self.shape, args, dsid=self.id)\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/site-packages/h5py/_hl/selections.py\", line 94, in select\n",
      "    sel[args]\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/site-packages/h5py/_hl/dataset.py\", line 325, in __init__\n",
      "    self._dcpl = self.id.get_create_plist()\n",
      "  File \"h5py/h5o.pyx\", line 190, in h5py.h5o.open\n",
      "  File \"h5py/h5o.pyx\", line 190, in h5py.h5o.open\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/site-packages/h5py/_hl/selections.py\", line 261, in __getitem__\n",
      "    start, count, step, scalar = _handle_simple(self.shape,args)\n",
      "KeyboardInterrupt\n",
      "  File \"h5py/h5i.pyx\", line 40, in h5py.h5i.wrap_identifier\n",
      "  File \"h5py/h5i.pyx\", line 40, in h5py.h5i.wrap_identifier\n",
      "Traceback (most recent call last):\n",
      "KeyboardInterrupt\n",
      "  File \"<frozen importlib._bootstrap>\", line 416, in parent\n",
      "  File \"<frozen importlib._bootstrap>\", line 416, in parent\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/pma/chofer/repositories/chofer_tda_datasets/chofer_tda_datasets/utils/h5py_dataset.py\", line 28, in __getitem__\n",
      "    x = t(x)\n",
      "  File \"<ipython-input-1-57560b352926>\", line 55, in <lambda>\n",
      "    lambda x: coordinate_transform(x)),\n",
      "  File \"/home/pma/chofer/repositories/chofer_torchex/chofer_torchex/utils/functional.py\", line 14, in collection_cascade\n",
      "    function_to_apply=function_to_apply) for k, v in input.items()}\n",
      "  File \"/home/pma/chofer/repositories/chofer_torchex/chofer_torchex/utils/functional.py\", line 14, in <dictcomp>\n",
      "    function_to_apply=function_to_apply) for k, v in input.items()}\n",
      "  File \"/home/pma/chofer/repositories/chofer_torchex/chofer_torchex/utils/functional.py\", line 14, in collection_cascade\n",
      "    function_to_apply=function_to_apply) for k, v in input.items()}\n",
      "  File \"/home/pma/chofer/repositories/chofer_torchex/chofer_torchex/utils/functional.py\", line 14, in <dictcomp>\n",
      "    function_to_apply=function_to_apply) for k, v in input.items()}\n",
      "  File \"/home/pma/chofer/repositories/chofer_torchex/chofer_torchex/utils/functional.py\", line 6, in collection_cascade\n",
      "    return function_to_apply(input)\n",
      "  File \"<ipython-input-1-57560b352926>\", line 55, in <lambda>\n",
      "    lambda x: coordinate_transform(x)),\n",
      "  File \"/home/pma/chofer/repositories/chofer_torchex/chofer_torchex/nn/slayer.py\", line 396, in __call__\n",
      "    y[i] = - self._nu_squared/y[i] + self._2_nu\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/site-packages/torch/tensor.py\", line 346, in __rdiv__\n",
      "    return self.new().resize_as_(self).fill_(other).div_(self)\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/site-packages/torch/tensor.py\", line 27, in new\n",
      "    return self.__class__(*args, **kwargs)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-4-8ee2feb1fddc>\", line 107, in <module>\n",
      "    experiment()\n",
      "  File \"<ipython-input-4-8ee2feb1fddc>\", line 47, in experiment\n",
      "    for i_batch, (x, y) in enumerate(dl_train, 1):\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 275, in __next__\n",
      "    idx, batch = self._get_batch()\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 254, in _get_batch\n",
      "    return self.data_queue.get()\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/site-packages/torch/multiprocessing/reductions.py\", line 70, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/multiprocessing/resource_sharer.py\", line 87, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 493, in Client\n",
      "    answer_challenge(c, authkey)\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 732, in answer_challenge\n",
      "    message = connection.recv_bytes(256)         # reject large message\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 1828, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1090, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/inspect.py\", line 1483, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/inspect.py\", line 1441, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/inspect.py\", line 687, in getsourcefile\n",
      "    if any(filename.endswith(s) for s in all_bytecode_suffixes):\n",
      "  File \"/scratch2/chofer/opt/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 175, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 25338) exited unexpectedly with exit code 1.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "stats_of_runs = []\n",
    "def experiment():   \n",
    "    \n",
    "    splitter = StratifiedShuffleSplit(n_splits=10, \n",
    "                                      train_size=train_env.train_size, \n",
    "                                      test_size=1-train_env.train_size, \n",
    "                                      random_state=123)\n",
    "    train_test_splits = list(splitter.split(X=dataset.targets, y=dataset.targets))\n",
    "    train_test_splits = [(train_i.tolist(), test_i.tolist()) for train_i, test_i in train_test_splits]\n",
    "    \n",
    "    for run_i, (train_i, test_i) in enumerate(train_test_splits):\n",
    "        print('')\n",
    "        print('Run', run_i)     \n",
    "\n",
    "        model = Scine01Model()\n",
    "#         model.center_init([dataset[i] for i in train_i])\n",
    "        model.cuda()\n",
    "\n",
    "        stats = defaultdict(list)\n",
    "        stats_of_runs.append(stats)\n",
    "        \n",
    "        opt = torch.optim.SGD(model.parameters(), lr=train_env.lr_initial, momentum=train_env.momentum)\n",
    "\n",
    "        for i_epoch in range(1, train_env.n_epochs+1):      \n",
    "\n",
    "            model.train()\n",
    "            \n",
    "            train_sampler = [i for i in train_i]\n",
    "            random.shuffle(train_sampler)\n",
    "            dl_train = DataLoader(dataset,\n",
    "                              batch_size=train_env.batch_size, \n",
    "                              collate_fn=collate_fn,\n",
    "                              sampler=train_sampler, \n",
    "                              num_workers=10)\n",
    "\n",
    "            dl_test = DataLoader(dataset,\n",
    "                                 batch_size=train_env.batch_size, \n",
    "                                 collate_fn=collate_fn, \n",
    "                                 sampler=test_i,\n",
    "                                 num_workers=10)\n",
    "\n",
    "            epoch_loss = 0    \n",
    "\n",
    "            if i_epoch % train_env.lr_epoch_step == 0:\n",
    "                adapt_lr(opt, lambda lr: lr*0.5)\n",
    "\n",
    "            for i_batch, (x, y) in enumerate(dl_train, 1):    \n",
    "                \n",
    "                x = collection_cascade(x,\n",
    "                                       lambda xx: isinstance(xx, tuple),\n",
    "                                       lambda xx: (xx[0].cuda(), xx[1].cuda(), xx[2], xx[3]))\n",
    "                y = y.cuda()\n",
    "\n",
    "                y = torch.autograd.Variable(y)\n",
    "\n",
    "                def closure():\n",
    "                    opt.zero_grad()\n",
    "                    y_hat = model(x)            \n",
    "                    loss = nn.functional.cross_entropy(y_hat, y)   \n",
    "                    loss.backward()\n",
    "                    return loss\n",
    "\n",
    "                loss = opt.step(closure)\n",
    "\n",
    "                epoch_loss += float(loss)\n",
    "                stats['loss_by_batch'].append(float(loss))\n",
    "                stats['centers'].append(model.slayers['top'][sensor_indices[0]][0].centers.data.cpu().numpy())\n",
    "\n",
    "                print(\"Epoch {}/{}, Batch {}/{}\".format(i_epoch, train_env.n_epochs, i_batch, len(dl_train)), end=\"       \\r\")\n",
    "\n",
    "            stats['train_loss_by_epoch'].append(epoch_loss/len(dl_train))            \n",
    "                     \n",
    "            model.eval()    \n",
    "            true_samples = 0\n",
    "            seen_samples = 0\n",
    "            epoch_test_loss = 0\n",
    "            confusion_matrix = np.zeros((7, 7))\n",
    "            \n",
    "            for i_batch, (x, y) in enumerate(dl_test):\n",
    "                \n",
    "                x = collection_cascade(x,\n",
    "                                       lambda xx: isinstance(xx, tuple),\n",
    "                                       lambda xx: (xx[0].cuda(), xx[1].cuda(), xx[2], xx[3]))\n",
    "                y = y.cuda()\n",
    "\n",
    "                y_hat = model(x)\n",
    "                epoch_test_loss += float(nn.functional.cross_entropy(y_hat, torch.autograd.Variable(y.cuda())).data)\n",
    "                \n",
    "                y_hat = y_hat.max(dim=1)[1].data.long()\n",
    "                \n",
    "                for y_i_true, y_i_pred in zip(y, y_hat):\n",
    "                    confusion_matrix[y_i_true, y_i_pred] += 1\n",
    "\n",
    "                true_samples += (y_hat == y).sum()\n",
    "                seen_samples += y.size(0)  \n",
    "\n",
    "            stats['test_accuracy'].append(true_samples/seen_samples)\n",
    "            stats['test_loss_by_epoch'].append(epoch_test_loss/len(dl_test))\n",
    "            stats['confusion_matrix'] = confusion_matrix\n",
    "            print('')\n",
    "            print(true_samples/seen_samples)\n",
    "            \n",
    "        print('')\n",
    "        print('acc.', np.mean(stats['test_accuracy'][-10:]))\n",
    "#     return stats_of_runs\n",
    "\n",
    "experiment()\n",
    "# stats_of_runs = experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean([np.mean(s['test_accuracy'][-10:]) for s in stats_of_runs]))\n",
    "[np.mean(s['test_accuracy'][-10:]) for s in stats_of_runs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "stats = stats_of_runs[0]\n",
    "c_start = stats['centers'][0]\n",
    "c_end = stats['centers'][-1]\n",
    "\n",
    "plt.plot(c_start[:,0], c_start[:, 1], 'bo', label='center initialization')\n",
    "plt.plot(c_end[:,0], c_end[:, 1], 'ro', label='center learned')\n",
    "\n",
    "all_centers = numpy.stack(stats['centers'], axis=0)\n",
    "for i in range(all_centers.shape[1]):\n",
    "    points = all_centers[:,i, :]\n",
    "    plt.plot(points[:, 0], points[:, 1], '-k')\n",
    "    \n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(stats['train_loss_by_epoch'], label='train_loss')\n",
    "plt.plot(stats['test_loss_by_epoch'], label='test_loss')\n",
    "plt.plot(stats['test_accuracy'])\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = SciNe01EEGBottomTopFiltration(data_root_folder_path='../chofer_tda_datasets/data_generated/')\n",
    "indices = [str(i) for i in data_set.sensor_configurations['all']]\n",
    "selector = Hdf5GroupToDictSelector({'top': indices, 'bottom': indices})\n",
    "data_set.data_transforms.append(selector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
